{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c869f71",
   "metadata": {},
   "source": [
    "# CRM Sales Dashboard Data Validation and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a55cf721",
   "metadata": {},
   "source": [
    "Avinash Bisram (8/27/24)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff1201e",
   "metadata": {},
   "source": [
    "**Description:** Data Validation and Cleaning to prepare the necessary data files for constructing the CRM Sales Dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35602333",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Plan:\n",
    "\n",
    "# Import packages\n",
    "# Load raw tables\n",
    "# Data Validation\n",
    "    # Correct data types\n",
    "    # Resolve typos and logical duplicates (also check for diff encoded blanks)\n",
    "    # Check for duplicates\n",
    "    # Report null values (and deal with them if necessary)\n",
    "    # Report outliers (and deal with them if necessary)\n",
    "# Data Profiling\n",
    "    # Just understanding the data in general\n",
    "    # This data has a data dictionary which is great\n",
    "# EDA (?)\n",
    "# Prepare data to be used in dashboarding\n",
    "# Export clean data and final data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ded8c1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Removing row and column limits for pandas DataFrames\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ab3349f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['accounts.csv',\n",
       " 'accounts_CLEAN.csv',\n",
       " 'data_dictionary.csv',\n",
       " 'products.csv',\n",
       " 'products_CLEAN.csv',\n",
       " 'sales_pipeline.csv',\n",
       " 'sales_pipeline_CLEAN.csv',\n",
       " 'sales_teams.csv',\n",
       " 'sales_teams_CLEAN.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List the tables we have in the Data folder\n",
    "\n",
    "os.listdir('./Data')\n",
    "\n",
    "# 5 tables\n",
    "# It looks like we have a data dictionary here as well so let's look at that first"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6fdb641",
   "metadata": {},
   "source": [
    "## Data QA (data_dictionary.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5387650",
   "metadata": {},
   "source": [
    "**Summary:** \n",
    "* data_dictionary.csv is simply a Data Dictionary telling us what information should be stored in each column of the tables we are looking at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d876aa4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21 entries, 0 to 20\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Table        21 non-null     object\n",
      " 1   Field        21 non-null     object\n",
      " 2   Description  21 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 632.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table</th>\n",
       "      <th>Field</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accounts</td>\n",
       "      <td>account</td>\n",
       "      <td>Company name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accounts</td>\n",
       "      <td>sector</td>\n",
       "      <td>Industry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accounts</td>\n",
       "      <td>year_established</td>\n",
       "      <td>Year Established</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accounts</td>\n",
       "      <td>revenue</td>\n",
       "      <td>Annual revenue (in millions of USD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accounts</td>\n",
       "      <td>employees</td>\n",
       "      <td>Number of employees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>accounts</td>\n",
       "      <td>office_location</td>\n",
       "      <td>Headquarters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>accounts</td>\n",
       "      <td>subsidiary_of</td>\n",
       "      <td>Parent company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>products</td>\n",
       "      <td>product</td>\n",
       "      <td>Product name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>products</td>\n",
       "      <td>series</td>\n",
       "      <td>Product series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>products</td>\n",
       "      <td>sales_price</td>\n",
       "      <td>Suggested retail price</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Table             Field                          Description\n",
       "0  accounts           account                         Company name\n",
       "1  accounts            sector                             Industry\n",
       "2  accounts  year_established                     Year Established\n",
       "3  accounts           revenue  Annual revenue (in millions of USD)\n",
       "4  accounts         employees                  Number of employees\n",
       "5  accounts   office_location                         Headquarters\n",
       "6  accounts     subsidiary_of                       Parent company\n",
       "7  products           product                         Product name\n",
       "8  products            series                       Product series\n",
       "9  products       sales_price               Suggested retail price"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the table\n",
    "\n",
    "df_raw_data_dictionary = pd.read_csv('./Data/data_dictionary.csv')\n",
    "\n",
    "# Display some general stats and the head of the table\n",
    "\n",
    "df_raw_data_dictionary.info()\n",
    "df_raw_data_dictionary.head(10)\n",
    "\n",
    "# 21 rows, 3 columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9373ac93",
   "metadata": {},
   "source": [
    "It looks like data_dictionary.csv is a description of each field/column in the various tables. It doesn't tell us what the data types of each field are supposed to be so we'll have to make our best guess based on the data within and how we'll be using it in our dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3563a661",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['accounts', 'products', 'sales_teams', 'sales_pipeline'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if every table is covered in this dictionary\n",
    "\n",
    "df_raw_data_dictionary['Table'].unique()\n",
    "\n",
    "# Looks like it because they are named the same as the CSV files. We can use this additional information going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dda05d",
   "metadata": {},
   "source": [
    "## Data QA (accounts.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67167778",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "\n",
    "* account column: A typo was found and resolved changing \"technolgy\" to \"technology\"\n",
    "* office_location column: A typo was found and resolved changing \"Philipines\" to \"Philippines\"\n",
    "* subsidiary_of column: 82% null values but we don't have to worry as nulls in this column are expected\n",
    "* 0 duplicates found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4a40663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table</th>\n",
       "      <th>Field</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>accounts</td>\n",
       "      <td>account</td>\n",
       "      <td>Company name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accounts</td>\n",
       "      <td>sector</td>\n",
       "      <td>Industry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accounts</td>\n",
       "      <td>year_established</td>\n",
       "      <td>Year Established</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accounts</td>\n",
       "      <td>revenue</td>\n",
       "      <td>Annual revenue (in millions of USD)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accounts</td>\n",
       "      <td>employees</td>\n",
       "      <td>Number of employees</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>accounts</td>\n",
       "      <td>office_location</td>\n",
       "      <td>Headquarters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>accounts</td>\n",
       "      <td>subsidiary_of</td>\n",
       "      <td>Parent company</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Table             Field                          Description\n",
       "0  accounts           account                         Company name\n",
       "1  accounts            sector                             Industry\n",
       "2  accounts  year_established                     Year Established\n",
       "3  accounts           revenue  Annual revenue (in millions of USD)\n",
       "4  accounts         employees                  Number of employees\n",
       "5  accounts   office_location                         Headquarters\n",
       "6  accounts     subsidiary_of                       Parent company"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the relevant information from data_dictionary\n",
    "\n",
    "df_raw_data_dictionary[df_raw_data_dictionary['Table'] == \"accounts\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15636517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 85 entries, 0 to 84\n",
      "Data columns (total 7 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   account           85 non-null     object \n",
      " 1   sector            85 non-null     object \n",
      " 2   year_established  85 non-null     int64  \n",
      " 3   revenue           85 non-null     float64\n",
      " 4   employees         85 non-null     int64  \n",
      " 5   office_location   85 non-null     object \n",
      " 6   subsidiary_of     15 non-null     object \n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 4.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account</th>\n",
       "      <th>sector</th>\n",
       "      <th>year_established</th>\n",
       "      <th>revenue</th>\n",
       "      <th>employees</th>\n",
       "      <th>office_location</th>\n",
       "      <th>subsidiary_of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acme Corporation</td>\n",
       "      <td>technolgy</td>\n",
       "      <td>1996</td>\n",
       "      <td>1100.04</td>\n",
       "      <td>2822</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Betasoloin</td>\n",
       "      <td>medical</td>\n",
       "      <td>1999</td>\n",
       "      <td>251.41</td>\n",
       "      <td>495</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Betatech</td>\n",
       "      <td>medical</td>\n",
       "      <td>1986</td>\n",
       "      <td>647.18</td>\n",
       "      <td>1185</td>\n",
       "      <td>Kenya</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bioholding</td>\n",
       "      <td>medical</td>\n",
       "      <td>2012</td>\n",
       "      <td>587.34</td>\n",
       "      <td>1356</td>\n",
       "      <td>Philipines</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bioplex</td>\n",
       "      <td>medical</td>\n",
       "      <td>1991</td>\n",
       "      <td>326.82</td>\n",
       "      <td>1016</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Blackzim</td>\n",
       "      <td>retail</td>\n",
       "      <td>2009</td>\n",
       "      <td>497.11</td>\n",
       "      <td>1588</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bluth Company</td>\n",
       "      <td>technolgy</td>\n",
       "      <td>1993</td>\n",
       "      <td>1242.32</td>\n",
       "      <td>3027</td>\n",
       "      <td>United States</td>\n",
       "      <td>Acme Corporation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bubba Gump</td>\n",
       "      <td>software</td>\n",
       "      <td>2002</td>\n",
       "      <td>987.39</td>\n",
       "      <td>2253</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Cancity</td>\n",
       "      <td>retail</td>\n",
       "      <td>2001</td>\n",
       "      <td>718.62</td>\n",
       "      <td>2448</td>\n",
       "      <td>United States</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Cheers</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>1993</td>\n",
       "      <td>4269.90</td>\n",
       "      <td>6472</td>\n",
       "      <td>United States</td>\n",
       "      <td>Massive Dynamic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            account         sector  year_established  revenue  employees  \\\n",
       "0  Acme Corporation      technolgy              1996  1100.04       2822   \n",
       "1        Betasoloin        medical              1999   251.41        495   \n",
       "2          Betatech        medical              1986   647.18       1185   \n",
       "3        Bioholding        medical              2012   587.34       1356   \n",
       "4           Bioplex        medical              1991   326.82       1016   \n",
       "5          Blackzim         retail              2009   497.11       1588   \n",
       "6     Bluth Company      technolgy              1993  1242.32       3027   \n",
       "7        Bubba Gump       software              2002   987.39       2253   \n",
       "8           Cancity         retail              2001   718.62       2448   \n",
       "9            Cheers  entertainment              1993  4269.90       6472   \n",
       "\n",
       "  office_location     subsidiary_of  \n",
       "0   United States               NaN  \n",
       "1   United States               NaN  \n",
       "2           Kenya               NaN  \n",
       "3      Philipines               NaN  \n",
       "4   United States               NaN  \n",
       "5   United States               NaN  \n",
       "6   United States  Acme Corporation  \n",
       "7   United States               NaN  \n",
       "8   United States               NaN  \n",
       "9   United States   Massive Dynamic  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the table\n",
    "\n",
    "df_raw_accounts = pd.read_csv('./Data/accounts.csv')\n",
    "\n",
    "# Display some general stats and the head of the table\n",
    "\n",
    "df_raw_accounts.info()\n",
    "df_raw_accounts.head(10)\n",
    "\n",
    "# Shape: 85 rows, 7 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e63e0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Check if the data types of each column seem correct (based on the information we expect them to contain)\n",
    "\n",
    "# COLUMN_NAME           EXPECTED DATA TYPE OF VALUES      CURRENT DATA TYPE\n",
    "\n",
    "# account               string                            object (correct)\n",
    "# sector                string                            object (correct)\n",
    "# year_established      integer                           int64 (correct)\n",
    "# revenue               float/decimal                     float64 (correct)\n",
    "# employees             integer                           int64 (correct)\n",
    "# office_location       string                            object (correct)\n",
    "# subsidiary_of         string                            object (correct)\n",
    "\n",
    "# All data types of columns look good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10d9580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Resolve typos, logical duplicates, logical nulls\n",
    "# We want to do this before actually checking for duplicates because some values might mean the same but are recorded\n",
    "    # slightly different (lowercase vs. uppercase, null string values being '' or ' ', null int values being -1, etc.)\n",
    "    \n",
    "# Going through each column and looking at the unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e307da53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null count for account column: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 2a: account (object)\n",
    "\n",
    "# Quick check comparing current unique values and all lowercase values\n",
    "df_raw_accounts['account'].nunique() # 85 current unique values\n",
    "df_raw_accounts['account'].str.lower().nunique() # 85 lowercase unique values\n",
    "    # Same number means no need to change any values\n",
    "\n",
    "# Scanning through list of unique values for typos\n",
    "df_raw_accounts['account'].sort_values()\n",
    "    # Doesn't look like any typos besides one value \"dambase\" being lowercase while everything else is capitalized\n",
    "    # Let's leave it for now (in case we need to merge on this value) but keep in mind for the end\n",
    "\n",
    "# Logic check (based on data_dictionary)\n",
    "    # Are all these values company names? I don't recognize them but they could be fabricated for this project\n",
    "    \n",
    "# Logical null values?\n",
    "    # Since this is a string column, we would be checking for values like \"Unknown\", \"Blank\", etc.\n",
    "    # Also checking for any empty string \"\" which could have varying spaces contained like \" \", \"  \", etc.\n",
    "    # I don't see any so looks good\n",
    "\n",
    "# Count of real null values\n",
    "print(f\"Null count for account column: {df_raw_accounts['account'].isnull().sum()}\")\n",
    "    # No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a210be09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null count for sector column: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 2b: sector (object)\n",
    "\n",
    "# Compare current unique count and all lowercase count\n",
    "df_raw_accounts['sector'].nunique() # 10 current unique values\n",
    "df_raw_accounts['sector'].str.lower().nunique() # 10 lowercase unique values\n",
    "    # Same number = good\n",
    "\n",
    "# Look for typos in value list\n",
    "df_raw_accounts['sector'].unique()\n",
    "    # 'technolgy' is spelled wrong!\n",
    "\n",
    "# Resolving the typo from above (and noting the change in case we need to do joins later)\n",
    "indexes_to_change = df_raw_accounts[df_raw_accounts['sector'] == 'technolgy'].index\n",
    "\n",
    "for index in indexes_to_change:\n",
    "    df_raw_accounts.at[index,'sector'] = 'technology'\n",
    "\n",
    "# Checking the result\n",
    "df_raw_accounts['sector'].unique()\n",
    "    # Typo resolved\n",
    "\n",
    "# Logic check (based on data_dictionary)\n",
    "    # Are the values all Industry names? Yes they look correct\n",
    "\n",
    "# Logical null values?\n",
    "    # We didn't find any values that would otherwise indicate unknown or blank so NO logical null values here.\n",
    "    \n",
    "# Count of null values\n",
    "print(f\"Null count for sector column: {df_raw_accounts['sector'].isnull().sum()}\")\n",
    "    # No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d51524c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null count for year_established column: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 2c: year_established (int)\n",
    "\n",
    "# Logic check (based on data_dictionary)\n",
    "    # Are all the contained values valid years?\n",
    "df_raw_accounts['year_established'].describe()\n",
    "    # No glaring outliers in either direction so they look good\n",
    "    \n",
    "# Logical null values?\n",
    "    # We don't see any negative values that would usually indicate unknown integer values so all good here.\n",
    "\n",
    "# Count of null values\n",
    "print(f\"Null count for year_established column: {df_raw_accounts['year_established'].isnull().sum()}\")\n",
    "    # No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6aba4cda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null count for revenue column: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 2d: revenue (float/decimal)\n",
    "\n",
    "# Logic check (based on data_dictionary)\n",
    "    # Are all the contained values revenue (in millions of dollars)\n",
    "df_raw_accounts['revenue'].describe()\n",
    "    # Nothing seems extremely out of the ordinary but one company has revenue of 11 billion dollars.\n",
    "\n",
    "# Logical null values?\n",
    "    # Again we don't see any negative values (since this column would otherwise only hold positive values)\n",
    "\n",
    "# Count of null values\n",
    "print(f\"Null count for revenue column: {df_raw_accounts['revenue'].isnull().sum()}\")\n",
    "    # No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d5a7382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null count for employees column: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 2e: employees (int)\n",
    "\n",
    "# Logic check (based on data_dictionary)\n",
    "    # Are all the contained values valid employee counts?\n",
    "df_raw_accounts['employees'].describe()\n",
    "    # Values range from 9 to 34288 (seems believable if our company list contains a startup or small company)\n",
    "\n",
    "# Logical null values\n",
    "    # No negative values or otherwise strange values so all good.\n",
    "\n",
    "# Count of null values\n",
    "print(f\"Null count for employees column: {df_raw_accounts['employees'].isnull().sum()}\")\n",
    "    # No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "faf48235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null count for office_location column: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 2f: office_location (object)\n",
    "\n",
    "# Compare current unique count and all lowercase count\n",
    "df_raw_accounts['office_location'].nunique() # 15 current unique values\n",
    "df_raw_accounts['office_location'].str.lower().nunique() # 15 lowercase unique values\n",
    "    # Same number = good\n",
    "\n",
    "# Look for typos in value list\n",
    "df_raw_accounts['office_location'].unique()\n",
    "    # 'Philipines' spelled wrong! Should be 'Philippines'\n",
    "\n",
    "# Resolving the typo from above (and noting the change in case we need to do joins later)\n",
    "indexes_to_change = df_raw_accounts[df_raw_accounts['office_location'] == 'Philipines'].index\n",
    "\n",
    "for index in indexes_to_change:\n",
    "    df_raw_accounts.at[index,'office_location'] = 'Philippines'\n",
    "\n",
    "# Checking the result\n",
    "df_raw_accounts['office_location'].unique()\n",
    "    # Typo resolved\n",
    "\n",
    "# Logic check (based on data_dictionary)\n",
    "    # Are the values all location names? Yes they look correct (they represent countries)\n",
    "\n",
    "# Logical null values?\n",
    "    # We didn't find any values that would otherwise indicate unknown or blank so NO logical null values here.\n",
    "    \n",
    "# Count of null values\n",
    "print(f\"Null count for office_location column: {df_raw_accounts['office_location'].isnull().sum()}\")\n",
    "    # No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c9918eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null count for subsidiary_of column: 70\n"
     ]
    }
   ],
   "source": [
    "# Step 2g: subsidiary_of (object)\n",
    "\n",
    "# Compare current unique count and all lowercase unique count\n",
    "df_raw_accounts['subsidiary_of'].nunique() # 7 current unique values\n",
    "df_raw_accounts['subsidiary_of'].str.lower().nunique() # 7 lowercase unique values\n",
    "    # Same number = good\n",
    "\n",
    "# Look for typos in value list\n",
    "df_raw_accounts['subsidiary_of'].unique()\n",
    "    # No typos that we can see\n",
    "\n",
    "# Logic check (based on data_dictionary)\n",
    "    # Are all the values all parent_company names? (If so, all values should be present in the account column)\n",
    "unique_subsidiaries = set(df_raw_accounts['subsidiary_of'].unique()[1:]) # ignoring nan\n",
    "\n",
    "# Checking if all these values are present in the accounts column using sets\n",
    "unique_parent_companies = set(df_raw_accounts['account'].unique())\n",
    "unique_parent_companies\n",
    "\n",
    "unique_subsidiaries.difference(unique_parent_companies) # Empty set means all subsidiaries are valid!\n",
    "\n",
    "# Logical null values\n",
    "df_raw_accounts['subsidiary_of'].unique()\n",
    "    # No empty or filler values (Unknown, empty, blank, etc.)\n",
    "\n",
    "# Count of null values\n",
    "print(f\"Null count for subsidiary_of column: {df_raw_accounts['subsidiary_of'].isnull().sum()}\")\n",
    "    # 70 null values (there are only 85 rows so this is 82%)\n",
    "    # However this makes sense because we expect most companies to be standalone and not subsidiaries of others.\n",
    "    # We don't have to do anything to these null values since our final deliverable is a dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2b9b8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Checking for duplicates\n",
    "\n",
    "df_raw_accounts.duplicated().sum()\n",
    "\n",
    "# No duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3b9ea86",
   "metadata": {},
   "source": [
    "## Data QA (products.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4e6562b",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "* sales_price column: datatype MAY need to be changed from int to float_decimal but it can easily be done in our dashboarding tool so for now it's not an issue until we look at the other tables. Adding it to our notes for now.\n",
    "* 0 duplicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "820a292a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table</th>\n",
       "      <th>Field</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>products</td>\n",
       "      <td>product</td>\n",
       "      <td>Product name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>products</td>\n",
       "      <td>series</td>\n",
       "      <td>Product series</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>products</td>\n",
       "      <td>sales_price</td>\n",
       "      <td>Suggested retail price</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Table        Field             Description\n",
       "7  products      product            Product name\n",
       "8  products       series          Product series\n",
       "9  products  sales_price  Suggested retail price"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the relevant information from data_dictionary\n",
    "\n",
    "df_raw_data_dictionary[df_raw_data_dictionary['Table'] == \"products\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22809e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7 entries, 0 to 6\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   product      7 non-null      object\n",
      " 1   series       7 non-null      object\n",
      " 2   sales_price  7 non-null      int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 296.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>product</th>\n",
       "      <th>series</th>\n",
       "      <th>sales_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GTX Basic</td>\n",
       "      <td>GTX</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GTX Pro</td>\n",
       "      <td>GTX</td>\n",
       "      <td>4821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MG Special</td>\n",
       "      <td>MG</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MG Advanced</td>\n",
       "      <td>MG</td>\n",
       "      <td>3393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GTX Plus Pro</td>\n",
       "      <td>GTX</td>\n",
       "      <td>5482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GTX Plus Basic</td>\n",
       "      <td>GTX</td>\n",
       "      <td>1096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GTK 500</td>\n",
       "      <td>GTK</td>\n",
       "      <td>26768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          product series  sales_price\n",
       "0       GTX Basic    GTX          550\n",
       "1         GTX Pro    GTX         4821\n",
       "2      MG Special     MG           55\n",
       "3     MG Advanced     MG         3393\n",
       "4    GTX Plus Pro    GTX         5482\n",
       "5  GTX Plus Basic    GTX         1096\n",
       "6         GTK 500    GTK        26768"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the table\n",
    "\n",
    "df_raw_products = pd.read_csv('./Data/products.csv')\n",
    "\n",
    "# Display some general stats and the head of the table\n",
    "\n",
    "df_raw_products.info()\n",
    "df_raw_products.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae33e5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Check if the data types of each column seem correct\n",
    "\n",
    "# COLUMN_NAME   EXPECTED DATA TYPE OF VALUES      CURRENT DATA TYPE\n",
    "# product       string                            object (correct)     \n",
    "# series        string                            object (correct)\n",
    "# sales_price   float/decimal                     int (not a huge issue honestly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35c6d82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Resolve typos, logical duplicates, logical nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "69cc0514",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2a: product (object)\n",
    "\n",
    "# Note: This table is so small we can do a lot of this work by eye\n",
    "\n",
    "# Compare current unique count and all lowercase unique count\n",
    "    # Good\n",
    "\n",
    "# Look for typos in value list\n",
    "    # No apparent typos (most product are of the GTX series and one GTK but the series of that value matches)\n",
    "\n",
    "# Logic check (based on data_dictionary)\n",
    "    # Are all of these values product names? Yes\n",
    "\n",
    "# Logical null values\n",
    "    # No logical null values that we can see\n",
    "\n",
    "# Count of null values\n",
    "    # No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab66a30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2b: series (object) \n",
    "\n",
    "# Compare current unique count and all lowercase unique count\n",
    "    # Good\n",
    "\n",
    "# Look for typos in value list\n",
    "    # No apparent typos\n",
    "\n",
    "# Logic check (based on data_dictionary)\n",
    "    # Are all of these values product series? Yes, they represent the prefix of each product\n",
    "\n",
    "# Logical null values\n",
    "    # No logical null values that we can see\n",
    "\n",
    "# Count of null values\n",
    "    # No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d38fca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count        7.000000\n",
       "mean      6023.571429\n",
       "std       9388.428070\n",
       "min         55.000000\n",
       "25%        823.000000\n",
       "50%       3393.000000\n",
       "75%       5151.500000\n",
       "max      26768.000000\n",
       "Name: sales_price, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2c: sales_price (int)\n",
    "\n",
    "# Logic check (based on data_dictionary)\n",
    "    # Are all the contained values valid sales prices?\n",
    "df_raw_products['sales_price'].describe()\n",
    "    # Values range from 55 dollars to 26768. We can't really confirm if any of this is wrong without currencies listed.\n",
    "\n",
    "# Logical null values\n",
    "    # No negative values or otherwise strange values so all good.\n",
    "\n",
    "# Count of null values\n",
    "    # No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "75648880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Check for duplicates\n",
    "\n",
    "df_raw_products.duplicated().sum()\n",
    "\n",
    "# No duplicates found"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb2ddec",
   "metadata": {},
   "source": [
    "## Data QA (sales_pipeline.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c68b73",
   "metadata": {},
   "source": [
    "**Summary:**\n",
    "* product column: resolved typo changing \"GTXPro\" to \"GTX Pro\"\n",
    "* account column: A LOT of missing values for engaging and prospecting deals but we won't be using the account field in our dashboard (thinking ahead) so we can ignore this time\n",
    "* engage_date column: Prospecting deals have no engage_date and all other deal stages do have a value for this column\n",
    "* close_date column: Engaging/Prospecting deals have no close dates while Won/Lost all have close dates\n",
    "* close_value column: Confirmed that all prospecting and engaging have no close values while lost deals have values of 0\n",
    "* 0 duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c6d846f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table</th>\n",
       "      <th>Field</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>sales_pipeline</td>\n",
       "      <td>opportunity_id</td>\n",
       "      <td>Unique identifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>sales_pipeline</td>\n",
       "      <td>sales_agent</td>\n",
       "      <td>Sales agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>sales_pipeline</td>\n",
       "      <td>product</td>\n",
       "      <td>Product name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>sales_pipeline</td>\n",
       "      <td>account</td>\n",
       "      <td>Company name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sales_pipeline</td>\n",
       "      <td>deal_stage</td>\n",
       "      <td>Sales pipeline stage (Prospecting &gt; Engaging &gt; Won / Lost)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>sales_pipeline</td>\n",
       "      <td>engage_date</td>\n",
       "      <td>Date in which the \"Engaging\" deal stage was initiated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sales_pipeline</td>\n",
       "      <td>close_date</td>\n",
       "      <td>Date in which the deal was \"Won\" or \"Lost\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sales_pipeline</td>\n",
       "      <td>close_value</td>\n",
       "      <td>Revenue from the deal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Table           Field  \\\n",
       "13  sales_pipeline  opportunity_id   \n",
       "14  sales_pipeline     sales_agent   \n",
       "15  sales_pipeline         product   \n",
       "16  sales_pipeline         account   \n",
       "17  sales_pipeline      deal_stage   \n",
       "18  sales_pipeline     engage_date   \n",
       "19  sales_pipeline      close_date   \n",
       "20  sales_pipeline     close_value   \n",
       "\n",
       "                                                   Description  \n",
       "13                                           Unique identifier  \n",
       "14                                                Sales agent   \n",
       "15                                                Product name  \n",
       "16                                                Company name  \n",
       "17  Sales pipeline stage (Prospecting > Engaging > Won / Lost)  \n",
       "18       Date in which the \"Engaging\" deal stage was initiated  \n",
       "19                  Date in which the deal was \"Won\" or \"Lost\"  \n",
       "20                                       Revenue from the deal  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the relevant information from data_dictionary\n",
    "\n",
    "df_raw_data_dictionary[df_raw_data_dictionary['Table'] == \"sales_pipeline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "35449d2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8800 entries, 0 to 8799\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   opportunity_id  8800 non-null   object \n",
      " 1   sales_agent     8800 non-null   object \n",
      " 2   product         8800 non-null   object \n",
      " 3   account         7375 non-null   object \n",
      " 4   deal_stage      8800 non-null   object \n",
      " 5   engage_date     8300 non-null   object \n",
      " 6   close_date      6711 non-null   object \n",
      " 7   close_value     6711 non-null   float64\n",
      "dtypes: float64(1), object(7)\n",
      "memory usage: 550.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>opportunity_id</th>\n",
       "      <th>sales_agent</th>\n",
       "      <th>product</th>\n",
       "      <th>account</th>\n",
       "      <th>deal_stage</th>\n",
       "      <th>engage_date</th>\n",
       "      <th>close_date</th>\n",
       "      <th>close_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1C1I7A6R</td>\n",
       "      <td>Moses Frase</td>\n",
       "      <td>GTX Plus Basic</td>\n",
       "      <td>Cancity</td>\n",
       "      <td>Won</td>\n",
       "      <td>2016-10-20</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>1054.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Z063OYW0</td>\n",
       "      <td>Darcel Schlecht</td>\n",
       "      <td>GTXPro</td>\n",
       "      <td>Isdom</td>\n",
       "      <td>Won</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>2017-03-11</td>\n",
       "      <td>4514.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EC4QE1BX</td>\n",
       "      <td>Darcel Schlecht</td>\n",
       "      <td>MG Special</td>\n",
       "      <td>Cancity</td>\n",
       "      <td>Won</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>2017-03-07</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MV1LWRNH</td>\n",
       "      <td>Moses Frase</td>\n",
       "      <td>GTX Basic</td>\n",
       "      <td>Codehow</td>\n",
       "      <td>Won</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>2017-03-09</td>\n",
       "      <td>588.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PE84CX4O</td>\n",
       "      <td>Zane Levy</td>\n",
       "      <td>GTX Basic</td>\n",
       "      <td>Hatfan</td>\n",
       "      <td>Won</td>\n",
       "      <td>2016-10-25</td>\n",
       "      <td>2017-03-02</td>\n",
       "      <td>517.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ZNBS69V1</td>\n",
       "      <td>Anna Snelling</td>\n",
       "      <td>MG Special</td>\n",
       "      <td>Ron-tech</td>\n",
       "      <td>Won</td>\n",
       "      <td>2016-10-29</td>\n",
       "      <td>2017-03-01</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9ME3374G</td>\n",
       "      <td>Vicki Laflamme</td>\n",
       "      <td>MG Special</td>\n",
       "      <td>J-Texon</td>\n",
       "      <td>Won</td>\n",
       "      <td>2016-10-30</td>\n",
       "      <td>2017-03-02</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7GN8Q4LL</td>\n",
       "      <td>Markita Hansen</td>\n",
       "      <td>GTX Basic</td>\n",
       "      <td>Cheers</td>\n",
       "      <td>Won</td>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>2017-03-07</td>\n",
       "      <td>601.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>OLK9LKZB</td>\n",
       "      <td>Niesha Huffines</td>\n",
       "      <td>GTX Plus Basic</td>\n",
       "      <td>Zumgoity</td>\n",
       "      <td>Won</td>\n",
       "      <td>2016-11-01</td>\n",
       "      <td>2017-03-03</td>\n",
       "      <td>1026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>HAXMC4IX</td>\n",
       "      <td>James Ascencio</td>\n",
       "      <td>MG Advanced</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Engaging</td>\n",
       "      <td>2016-11-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  opportunity_id      sales_agent         product   account deal_stage  \\\n",
       "0       1C1I7A6R      Moses Frase  GTX Plus Basic   Cancity        Won   \n",
       "1       Z063OYW0  Darcel Schlecht          GTXPro     Isdom        Won   \n",
       "2       EC4QE1BX  Darcel Schlecht      MG Special   Cancity        Won   \n",
       "3       MV1LWRNH      Moses Frase       GTX Basic   Codehow        Won   \n",
       "4       PE84CX4O        Zane Levy       GTX Basic    Hatfan        Won   \n",
       "5       ZNBS69V1    Anna Snelling      MG Special  Ron-tech        Won   \n",
       "6       9ME3374G   Vicki Laflamme      MG Special   J-Texon        Won   \n",
       "7       7GN8Q4LL   Markita Hansen       GTX Basic    Cheers        Won   \n",
       "8       OLK9LKZB  Niesha Huffines  GTX Plus Basic  Zumgoity        Won   \n",
       "9       HAXMC4IX   James Ascencio     MG Advanced       NaN   Engaging   \n",
       "\n",
       "  engage_date  close_date  close_value  \n",
       "0  2016-10-20  2017-03-01       1054.0  \n",
       "1  2016-10-25  2017-03-11       4514.0  \n",
       "2  2016-10-25  2017-03-07         50.0  \n",
       "3  2016-10-25  2017-03-09        588.0  \n",
       "4  2016-10-25  2017-03-02        517.0  \n",
       "5  2016-10-29  2017-03-01         49.0  \n",
       "6  2016-10-30  2017-03-02         57.0  \n",
       "7  2016-11-01  2017-03-07        601.0  \n",
       "8  2016-11-01  2017-03-03       1026.0  \n",
       "9  2016-11-03         NaN          NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the table\n",
    "\n",
    "df_raw_sales_pipeline = pd.read_csv('./Data/sales_pipeline.csv')\n",
    "\n",
    "# Display some general stats and the head of the table\n",
    "\n",
    "df_raw_sales_pipeline.info()\n",
    "df_raw_sales_pipeline.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55c5081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Check if the data types of each column seem correct\n",
    "\n",
    "# COLUMN_NAME           EXPECTED DATA TYPE OF VALUES      CURRENT DATA TYPE\n",
    "\n",
    "# opportunity_id        string or int?                    object (correct)\n",
    "# sales_agent           string                            object (correct)\n",
    "# product               string                            object (correct)\n",
    "# account               string                            object (correct)\n",
    "# deal_stage            string                            object (correct)\n",
    "# engage_date           date                              object (WRONG)\n",
    "# close_date            date                              object (WRONG)\n",
    "# close_value           int or float                      float64 (correct)\n",
    "\n",
    "# The two date columns are strings instead of dates\n",
    "# Our dashboard software can convert them but we want to do it here so we can check the range and any strange values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b0beadb4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "engage_date    datetime64[ns]\n",
       "close_date     datetime64[ns]\n",
       "dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Casting the two date columns as dates\n",
    "\n",
    "# Engage date (yyyy-mm-dd)\n",
    "df_raw_sales_pipeline['engage_date'] = pd.to_datetime(df_raw_sales_pipeline['engage_date'])\n",
    "\n",
    "# Close date (yyyy)\n",
    "df_raw_sales_pipeline['close_date'] = pd.to_datetime(df_raw_sales_pipeline['close_date'])\n",
    "\n",
    "# Inspecting the dtypes again\n",
    "df_raw_sales_pipeline[['engage_date','close_date']].dtypes\n",
    "\n",
    "# Looks better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e1e599a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Resolve typos, logical duplicates, logical nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "30ea09a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null count for opportunity_id column: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 2a: opportunity_id (object)\n",
    "\n",
    "# Compare current unique count to unique count after lowercase and eliminating whitespace\n",
    "df_raw_sales_pipeline['opportunity_id'].nunique() # 8800 unique values\n",
    "df_raw_sales_pipeline['opportunity_id'].str.lower().str.strip().nunique() # 8800 unique values\n",
    "    # Same number = good\n",
    "\n",
    "# Look for typos in value list\n",
    "    # If this is a unique identifier, we can't find typos the normal way\n",
    "    # Looks like there isn't a clear pattern of letter+number combos but we can at least check the length\n",
    "df_raw_sales_pipeline[df_raw_sales_pipeline['opportunity_id'].str.len() != 8]\n",
    "    # no values with lengths other than 8\n",
    "    \n",
    "# Logic check (based on data dictionary)\n",
    "    # We already confirmed that these values are unique identifiers (because nunique = num records)\n",
    "\n",
    "# Logical null values\n",
    "    # The only option since every row has SOME value is an eight-letter word used to express nulls but safe to assume\n",
    "    # they are not present (if they are we can still safely treat them as unique identifiers)\n",
    "\n",
    "# Count of null values\n",
    "print(f\"Null count for opportunity_id column: {df_raw_sales_pipeline['opportunity_id'].isnull().sum()}\")\n",
    "    # No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29c2e8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should have made this helper function a long time ago\n",
    "\n",
    "# Compares the unique count of a series to the unique count after lowercase and trimming\n",
    "def compareUniqueCounts(series) -> bool:\n",
    "    return series.nunique() == series.str.lower().str.strip().nunique()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f2dd2533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making another helper function to report null counts in a sentence\n",
    "\n",
    "def stateNullCount(dataframe, column) -> None:\n",
    "    print(f\"Null count for {column} column: {dataframe[column].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b25e1da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null count for sales_agent column: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 2b: sales_agent (object)\n",
    "\n",
    "# Compare current unique count to unique count after lowercase and eliminating whitespace\n",
    "compareUniqueCounts(df_raw_sales_pipeline['sales_agent']) # True = good\n",
    "\n",
    "# Look for typos\n",
    "sorted(df_raw_sales_pipeline['sales_agent'].unique())\n",
    "    # No typos that I can tell (because these are names)\n",
    "\n",
    "# Logical Check (based on data dictionary)\n",
    "    # Are these all names of sales agents? Without more information they appear so\n",
    "\n",
    "# Logical null values\n",
    "    # None. Checked while looking for typos\n",
    "\n",
    "# Count null values\n",
    "stateNullCount(df_raw_sales_pipeline, 'sales_agent')\n",
    "    # No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "66d43101",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null count for product column: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 2c: product (object)\n",
    "\n",
    "# Compare unique counts\n",
    "compareUniqueCounts(df_raw_sales_pipeline['product']) # True = good\n",
    "\n",
    "# Look for typos\n",
    "df_raw_sales_pipeline['product'].unique()\n",
    "\n",
    "# These should be the same values listed in the products table so let's compare the two lists\n",
    "set(df_raw_sales_pipeline['product'].unique()).difference(set(df_raw_products['product']))\n",
    "    # Found a typo! The product name should be \"GTX Pro\" not \"GTXPro\" (to match products table)\n",
    "\n",
    "# Changing that typo\n",
    "indexes_to_change = df_raw_sales_pipeline[df_raw_sales_pipeline['product'] == \"GTXPro\"].index\n",
    "\n",
    "for index in indexes_to_change:\n",
    "    df_raw_sales_pipeline.at[index,'product'] = \"GTX Pro\"\n",
    "\n",
    "# Check result\n",
    "set(df_raw_sales_pipeline['product'].unique()).difference(set(df_raw_products['product']))\n",
    "    # Success\n",
    "\n",
    "# Logic Check\n",
    "    # Done while finding the disjoint set\n",
    "    \n",
    "# Logical null values\n",
    "    # None. Easy check while looking for the disjoint set before\n",
    "\n",
    "# Count null values\n",
    "stateNullCount(df_raw_sales_pipeline, 'product')\n",
    "    # No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca71f7cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null count for account column: 1425\n"
     ]
    }
   ],
   "source": [
    "# Step 2d: account (object)\n",
    "\n",
    "# Compare unique counts\n",
    "compareUniqueCounts(df_raw_sales_pipeline['account']) # True = good\n",
    "\n",
    "# Look for typos + Logical check (based on data_dictionary)\n",
    "    # Same process as above comparing this unique set to that of the account table\n",
    "set(df_raw_sales_pipeline['account'].unique()).difference(set(df_raw_accounts['account']))\n",
    "    # One value in set (nan) meaning there are null values in this column\n",
    "\n",
    "# Logical null values\n",
    "    # Handled above as well (other placeholder values would have been present in the returned set)\n",
    "\n",
    "# Count null values\n",
    "stateNullCount(df_raw_sales_pipeline, 'account')\n",
    "    # 1425 null values (16% of records)\n",
    "\n",
    "# Why would there be null values in the account column of the sales_pipeline? Let's investigate\n",
    "#df_raw_sales_pipeline[df_raw_sales_pipeline['account'].isnull()]\n",
    "    # A mix of engaging and prospecting deals.\n",
    "    # Are these ALL the engaging and prospecting deals? (maybe the company is only added once the deal is closed?)\n",
    "\n",
    "# After skimming through rows of either Engaging or Prospecting deal stages\n",
    "    # Looks like MOST of the rows have missing accounts\n",
    "    # That is a bit strange but thinking ahead, we won't be using account in our dashboard so we can ignore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "560e6cb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null count for deal_stage column: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 2e: deal_stage (object)\n",
    "\n",
    "# Compare unique counts\n",
    "compareUniqueCounts(df_raw_sales_pipeline['deal_stage']) # True = good\n",
    "\n",
    "# Look for typos\n",
    "df_raw_sales_pipeline['deal_stage'].unique()\n",
    "    # Only 4 values and no typos that I can see\n",
    "\n",
    "# Logical null values\n",
    "    # Nope. Already checked from above\n",
    "\n",
    "# Logic check (based on data dictionary)\n",
    "    # The only four values that should be here are here so all good.\n",
    "\n",
    "# Count null values\n",
    "stateNullCount(df_raw_sales_pipeline, 'deal_stage')\n",
    "    # No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fd35d071",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null count for engage_date column: 500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2f: engage_date (datetime)\n",
    "\n",
    "# Checking the range of dates\n",
    "df_raw_sales_pipeline['engage_date'].describe()\n",
    "    # Range between 2016 and 2017\n",
    "\n",
    "# Logic check (based on data dictionary)\n",
    "    # They are definitely dates\n",
    "\n",
    "# Logical nulls?\n",
    "    # With dates, logical nulls may be encoded as extreme dates such as 1999-01-01 when the rest of dates are in 2016-2017.\n",
    "    # We don't see any of that here it seems\n",
    "\n",
    "# Typos?\n",
    "    # Check range of months\n",
    "df_raw_sales_pipeline['engage_date'].astype('str').str[5:7] # Between 1 and 12 (good)\n",
    "    # Check range of dates\n",
    "df_raw_sales_pipeline['engage_date'].astype('str').str[-2:] # Between 1 and 31 (good)\n",
    "\n",
    "# Count nulls\n",
    "stateNullCount(df_raw_sales_pipeline, 'engage_date')\n",
    "    # 500 nulls\n",
    "    \n",
    "# We expect this to be null for all rows that are prospecting and non-null otherwise\n",
    "df_raw_sales_pipeline[df_raw_sales_pipeline['deal_stage'] == \"Prospecting\"]['engage_date'].describe()\n",
    "    # Engage_date NULL for prospecting (good)\n",
    "df_raw_sales_pipeline[df_raw_sales_pipeline['deal_stage'] != \"Prospecting\"]['engage_date'].isnull().sum()\n",
    "    # Engage date NOT NULL for all other deal stages (good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fcb2a2b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null count for close_date column: 2089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2g: close_date (datetime)\n",
    "\n",
    "# Checking the range of dates\n",
    "df_raw_sales_pipeline['close_date'].describe()\n",
    "    # No strange outliers that I can see\n",
    "\n",
    "# Logic check (based on data dictionary)\n",
    "    # Again, these are definitely dates\n",
    "    \n",
    "# Logical nulls?\n",
    "    # No glaring ones from the range of values\n",
    "    \n",
    "# Typos?\n",
    "    # Check range of months\n",
    "df_raw_sales_pipeline['close_date'].astype('str').str[5:7] # Between 1 and 12 (good)\n",
    "    # Check range of dates\n",
    "df_raw_sales_pipeline['engage_date'].astype('str').str[-2:] # Between 1 and 31 (good)\n",
    "\n",
    "# Count nulls\n",
    "stateNullCount(df_raw_sales_pipeline, 'close_date')\n",
    "    # 2089 missing values, let's investigate\n",
    "    \n",
    "# We expect nulls to be for Prospecting and Engaging deals while Won/Lost should all have dates\n",
    "df_raw_sales_pipeline[(df_raw_sales_pipeline['deal_stage'] == \"Prospecting\") | (df_raw_sales_pipeline['deal_stage'] == \"Engaging\")]['close_date'].describe()\n",
    "    # All nulls for engaging and prospecting deals\n",
    "df_raw_sales_pipeline[(df_raw_sales_pipeline['deal_stage'] == \"Won\") | (df_raw_sales_pipeline['deal_stage'] == \"Lost\")]['close_date'].isnull().sum()\n",
    "    # No null values for Won or Lost deals\n",
    "    \n",
    "# Last check (all close dates SHOULD be >= engage dates when applicable)\n",
    "len(df_raw_sales_pipeline[df_raw_sales_pipeline['close_date'] < df_raw_sales_pipeline['engage_date']])\n",
    "    # 0 rows returned for the above query meaning our assumption is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "06cebc75",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null count for close_value column: 2089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    0.0\n",
       "mean     NaN\n",
       "std      NaN\n",
       "min      NaN\n",
       "25%      NaN\n",
       "50%      NaN\n",
       "75%      NaN\n",
       "max      NaN\n",
       "Name: close_value, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2h: close_value (float)\n",
    "\n",
    "# Checking the range\n",
    "df_raw_sales_pipeline['close_value'].describe()\n",
    "    # Max of 30K which seems believable because the highest price of the products offered was 26K.\n",
    "    # However a min of 0 dollars? Is the company giving away products for free? Let's investigate\n",
    "    \n",
    "#df_raw_sales_pipeline[df_raw_sales_pipeline['close_value'] == 0]\n",
    "    # Ok so looks like Lost deals are indicated with a close value of 0 which makes more sense\n",
    "\n",
    "# Let's double check that only happens for LOST deals\n",
    "df_raw_sales_pipeline[df_raw_sales_pipeline['close_value'] == 0]['deal_stage'].unique()\n",
    "df_raw_sales_pipeline[df_raw_sales_pipeline['deal_stage'] == 'Lost']['close_value'].describe()\n",
    "    # Yes the above is correct (Lost deals = 0 close value)\n",
    "\n",
    "# Checking for logical null values\n",
    "    # No negative values and we've sorted out the records with 0 so no logical nulls.\n",
    "\n",
    "# Logic check (based on data dictionary)\n",
    "    # The range of values seem correct\n",
    "\n",
    "# Count nulls\n",
    "stateNullCount(df_raw_sales_pipeline, 'close_value')\n",
    "    # 2089 nulls, let's investigate\n",
    "    \n",
    "df_raw_sales_pipeline[df_raw_sales_pipeline['close_value'].isnull()]\n",
    "    # Appears that Engaging and Prospecting deals have no close values (which makes sense)\n",
    "\n",
    "# Let's double check that this follows for ALL engaging and prospecting deals\n",
    "df_raw_sales_pipeline[(df_raw_sales_pipeline['deal_stage'] == \"Engaging\") | (df_raw_sales_pipeline['deal_stage'] == \"Prospecting\")]['close_value'].describe()\n",
    "    # Yup that follows for all engaging and prospecting deals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3ce42194",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Check for duplicates\n",
    "\n",
    "df_raw_sales_pipeline.duplicated().sum()\n",
    "    # No duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d1c158",
   "metadata": {},
   "source": [
    "## Data QA (sales_teams.csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6de9c82",
   "metadata": {},
   "source": [
    "**Summary**:\n",
    "* 0 duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3c4b8b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Table</th>\n",
       "      <th>Field</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>sales_teams</td>\n",
       "      <td>sales_agent</td>\n",
       "      <td>Sales agent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>sales_teams</td>\n",
       "      <td>manager</td>\n",
       "      <td>Respective sales manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sales_teams</td>\n",
       "      <td>regional_office</td>\n",
       "      <td>Regional office</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Table            Field               Description\n",
       "10  sales_teams      sales_agent               Sales agent\n",
       "11  sales_teams          manager  Respective sales manager\n",
       "12  sales_teams  regional_office           Regional office"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Displaying the relevant information from data_dictionary\n",
    "\n",
    "df_raw_data_dictionary[df_raw_data_dictionary['Table'] == \"sales_teams\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3383a155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 35 entries, 0 to 34\n",
      "Data columns (total 3 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   sales_agent      35 non-null     object\n",
      " 1   manager          35 non-null     object\n",
      " 2   regional_office  35 non-null     object\n",
      "dtypes: object(3)\n",
      "memory usage: 968.0+ bytes\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sales_agent</th>\n",
       "      <th>manager</th>\n",
       "      <th>regional_office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Anna Snelling</td>\n",
       "      <td>Dustin Brinkmann</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cecily Lampkin</td>\n",
       "      <td>Dustin Brinkmann</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Versie Hillebrand</td>\n",
       "      <td>Dustin Brinkmann</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lajuana Vencill</td>\n",
       "      <td>Dustin Brinkmann</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Moses Frase</td>\n",
       "      <td>Dustin Brinkmann</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jonathan Berthelot</td>\n",
       "      <td>Melvin Marxen</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Marty Freudenburg</td>\n",
       "      <td>Melvin Marxen</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Gladys Colclough</td>\n",
       "      <td>Melvin Marxen</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Niesha Huffines</td>\n",
       "      <td>Melvin Marxen</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Darcel Schlecht</td>\n",
       "      <td>Melvin Marxen</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          sales_agent           manager regional_office\n",
       "0       Anna Snelling  Dustin Brinkmann         Central\n",
       "1      Cecily Lampkin  Dustin Brinkmann         Central\n",
       "2   Versie Hillebrand  Dustin Brinkmann         Central\n",
       "3     Lajuana Vencill  Dustin Brinkmann         Central\n",
       "4         Moses Frase  Dustin Brinkmann         Central\n",
       "5  Jonathan Berthelot     Melvin Marxen         Central\n",
       "6   Marty Freudenburg     Melvin Marxen         Central\n",
       "7    Gladys Colclough     Melvin Marxen         Central\n",
       "8     Niesha Huffines     Melvin Marxen         Central\n",
       "9     Darcel Schlecht     Melvin Marxen         Central"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the table\n",
    "\n",
    "df_raw_sales_teams = pd.read_csv('./Data/sales_teams.csv')\n",
    "\n",
    "# Display some general stats and the head of the table\n",
    "\n",
    "df_raw_sales_teams.info()\n",
    "df_raw_sales_teams.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7e2e02d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Check if the data types of each column seem correct\n",
    "\n",
    "# COLUMN_NAME           EXPECTED DATA TYPE OF VALUES      CURRENT DATA TYPE\n",
    "# sales_agent           string                            object (correct)\n",
    "# manager               string                            object (correct)\n",
    "# regional_office       string                            object (correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0f6e7ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Resolve typos, logical duplicates, logical nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3ac59d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null count for sales_agent column: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 2a: sales_agent (object)\n",
    "\n",
    "# Compare current unique count and all lowercase unique count\n",
    "compareUniqueCounts(df_raw_sales_teams['sales_agent']) # True = good\n",
    "\n",
    "# Look for typos in value list + Logical Check (based on data dictionary)\n",
    "    # All unique values of agents from sales_pipeline should be present in this table\n",
    "set(df_raw_sales_pipeline['sales_agent'].unique()).difference(set(df_raw_sales_teams['sales_agent'].unique()))\n",
    "    # Empty set means all sales agents are present. Good!\n",
    "\n",
    "# Logical null values\n",
    "df_raw_sales_teams['sales_agent'].unique()\n",
    "    # Looks like every value is a real name so no logical nulls\n",
    "\n",
    "# Count of null values\n",
    "stateNullCount(df_raw_sales_teams, 'sales_agent')\n",
    "    # No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "66579a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null count for manager column: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 2b: manager (object)\n",
    "\n",
    "# Compare current unique count and all lowercase unique count\n",
    "compareUniqueCounts(df_raw_sales_teams['manager']) # True = good\n",
    "\n",
    "# Look for typos in value list\n",
    "df_raw_sales_teams['manager'].unique()\n",
    "    # 6 names and no glaring typos\n",
    "\n",
    "# Logic check (based on data_dictionary)\n",
    "    # These values should represent the names of managers and they appear correct\n",
    "    \n",
    "# Logical null values\n",
    "    # No logical nulls during check of unique values\n",
    "\n",
    "# Count of null values\n",
    "stateNullCount(df_raw_sales_teams, 'manager')\n",
    "    # No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d593839c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Null count for regional_office column: 0\n"
     ]
    }
   ],
   "source": [
    "# Step 2c: regional_office (object)\n",
    "\n",
    "# Compare current unique count and all lowercase unique count\n",
    "compareUniqueCounts(df_raw_sales_teams['regional_office']) # True = good\n",
    "\n",
    "# Look for typos in value list\n",
    "df_raw_sales_teams['regional_office'].unique()\n",
    "    # Only three values and they are all correct\n",
    "\n",
    "# Logic check (based on data_dictionary)\n",
    "    # These are all region locations (East, West, Central)\n",
    "\n",
    "# Logical null values\n",
    "    # None seen when inspecting unique values\n",
    "    \n",
    "# Count of null values\n",
    "stateNullCount(df_raw_sales_teams, 'regional_office')\n",
    "    # No null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e8d8704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Check for duplicates\n",
    "\n",
    "df_raw_sales_teams.duplicated().sum()\n",
    "\n",
    "# No duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a506fec",
   "metadata": {},
   "source": [
    "## Exporting the Cleaned Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "42728db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We didn't change data_dictionary.CSV so we can just save the others\n",
    "\n",
    "df_raw_accounts.to_csv('./Data/accounts_CLEAN.csv', index = False)\n",
    "df_raw_products.to_csv('./Data/products_CLEAN.csv', index = False)\n",
    "df_raw_sales_pipeline.to_csv('./Data/sales_pipeline_CLEAN.csv', index = False)\n",
    "df_raw_sales_teams.to_csv('./Data/sales_teams_CLEAN.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71a34c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outstanding Notes:\n",
    "# account table has one lowercase value \"dambase\" which we want to change to capitalized for consistency sake\n",
    "\n",
    "# products: sales_price is currently int instead of float but we'll see if this is an issue later\n",
    "    # Non-issue (we can convert in the dashboard software)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
